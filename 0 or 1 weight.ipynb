{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 885,
   "id": "10047d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "unit = []\n",
    "single = []\n",
    "tripple = []\n",
    "for i in range(0,100000):\n",
    "    single.append(random.randint(-100, 100))\n",
    "    \n",
    "for i in range(0,100000):\n",
    "    temp1 = random.randint(-10, 10)\n",
    "    temp2 = random.randint(-10, 10)\n",
    "    temp3 = random.randint(-10, 10)\n",
    "    tripple.append([temp1, temp2, temp3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "ee18ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(tripple)):\n",
    "    tripple[i].append(single[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "cd84d9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = tripple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "a8d437a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "answer = []\n",
    "for l in unit:\n",
    "    temp = False\n",
    "    if(l[0]>20 and abs(l[1] < 3) and abs(l[2] < 3) and abs(l[3] < 3)):\n",
    "        temp = True\n",
    "    if(l[1]>20 and abs(l[2] < 3) and abs(l[3] < 3) and abs(l[0] < 3)):\n",
    "        temp = True\n",
    "    if(l[2]>20 and abs(l[3] < 3) and abs(l[0] < 3) and abs(l[1] < 3)):\n",
    "        temp = True\n",
    "    if(l[3]>20 and abs(l[1] < 3) and abs(l[2] < 3) and abs(l[0] < 3)):\n",
    "        temp = True\n",
    "    answer.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "id": "7812d507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9336"
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for a in answer:\n",
    "    if(a==True):\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "id": "5c1384d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = tf.keras.utils.to_categorical(answer)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "id": "615b2923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2)"
      ]
     },
     "execution_count": 891,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "labels = np.array(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "49f1cb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 2)"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "id": "8ea5ec0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 4)"
      ]
     },
     "execution_count": 893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.array(unit)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0a0685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = tf.keras.models.Sequential()\n",
    "m0.add(tf.keras.layers.Dense(2, activation = \"softmax\", input_shape=(4,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e03d7293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 12)                60        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 52        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 122\n",
      "Trainable params: 122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7ad5d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "m0.compile(optimizer='rmsprop',\n",
    "                loss='mean_squared_error',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "2b5a117a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0445 - accuracy: 0.9381\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 738us/step - loss: 0.0445 - accuracy: 0.9382\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 697us/step - loss: 0.0445 - accuracy: 0.9380\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 776us/step - loss: 0.0445 - accuracy: 0.9380\n",
      "Epoch 5/10\n",
      " 782/1000 [======================>.......] - ETA: 0s - loss: 0.0445 - accuracy: 0.9380"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-342-51ea428cd1c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m0.fit(inputs,labels,epochs = 10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f2b17a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.36966568,  0.12533066],\n",
       "        [-0.6448173 , -0.89067745],\n",
       "        [ 0.05684882, -0.17444837],\n",
       "        [ 0.43259695,  0.47390565]], dtype=float32),\n",
       " array([ 2.6688612, -2.6688607], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m0.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "id": "6277c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = tf.keras.models.Sequential()\n",
    "m3.add(tf.keras.layers.Dense(4, activation = \"relu\", input_shape=(4,)))\n",
    "m3.add(tf.keras.layers.Dense(2, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "4a41862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = tf.keras.models.Sequential()\n",
    "for layer in m3.layers[:-1]:\n",
    "    m1.add(layer)\n",
    "m3 = m1\n",
    "m3.add(tf.keras.layers.Dense(12, activation = \"relu\", input_shape=(4,)))\n",
    "m3.add(tf.keras.layers.Dense(2, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "id": "cde773b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "id": "888cf7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_99 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "id": "e17bb2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.1894 - accuracy: 0.3793\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.7574 - accuracy: 0.4180\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 958us/step - loss: 1.4856 - accuracy: 0.4767\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 960us/step - loss: 0.4646 - accuracy: 0.7939\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 959us/step - loss: 0.2223 - accuracy: 0.9308\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1648 - accuracy: 0.9379\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 959us/step - loss: 0.1468 - accuracy: 0.9409\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1370 - accuracy: 0.9435\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9455\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1261 - accuracy: 0.9464\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 994us/step - loss: 0.1240 - accuracy: 0.9470\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1226 - accuracy: 0.9472\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 994us/step - loss: 0.1218 - accuracy: 0.9473\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 989us/step - loss: 0.1210 - accuracy: 0.9475\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1206 - accuracy: 0.9474\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.9476\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9477\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.94 - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9477\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9480\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.9482\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9483\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.9481\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.9482\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9486\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9485\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9485\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1173 - accuracy: 0.9485\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.9487\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9485\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.9488\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 989us/step - loss: 0.1167 - accuracy: 0.9489\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 989us/step - loss: 0.1163 - accuracy: 0.9493\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.9494\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.9494\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9493\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1156 - accuracy: 0.9493\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9495\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.9496\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9497\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.9497\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1145 - accuracy: 0.9493\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1142 - accuracy: 0.9498\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1140 - accuracy: 0.9499\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9498\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.9500\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9499\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 989us/step - loss: 0.1131 - accuracy: 0.9499\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.9499\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 999us/step - loss: 0.1124 - accuracy: 0.9500\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1121 - accuracy: 0.9500\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.9497\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.9500\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.9499\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9500\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 939us/step - loss: 0.1112 - accuracy: 0.9501\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 969us/step - loss: 0.1108 - accuracy: 0.9501\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 949us/step - loss: 0.1106 - accuracy: 0.9507\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 989us/step - loss: 0.1106 - accuracy: 0.9503\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 899us/step - loss: 0.1105 - accuracy: 0.9503\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.95 - 0s 939us/step - loss: 0.1105 - accuracy: 0.9505\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.9509\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1088 - accuracy: 0.95 - 0s 949us/step - loss: 0.1102 - accuracy: 0.9505\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9503\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9506\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9505\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9499\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9505\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9504\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9503\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1099 - accuracy: 0.9504\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 959us/step - loss: 0.1097 - accuracy: 0.9506\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9502\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9507\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9509\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9505\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.9505\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.9507\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9505\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9506\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 959us/step - loss: 0.1094 - accuracy: 0.9503\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 999us/step - loss: 0.1095 - accuracy: 0.9505\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 999us/step - loss: 0.1093 - accuracy: 0.9505\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 949us/step - loss: 0.1092 - accuracy: 0.9505\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 979us/step - loss: 0.1094 - accuracy: 0.9506\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 949us/step - loss: 0.1091 - accuracy: 0.9502\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.9505\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 959us/step - loss: 0.1093 - accuracy: 0.9507\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.9509: 0s - loss: 0.1098 - accuracy: 0.\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.9507\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.9506\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 979us/step - loss: 0.1093 - accuracy: 0.9502\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 969us/step - loss: 0.1092 - accuracy: 0.9504\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 989us/step - loss: 0.1092 - accuracy: 0.9507\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 989us/step - loss: 0.1090 - accuracy: 0.9507\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 969us/step - loss: 0.1089 - accuracy: 0.9507\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9505\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.9506\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.9507\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9508\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.9509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2603da8cfa0>"
      ]
     },
     "execution_count": 831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.fit(inputs,labels,epochs = 100, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "91e6300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 2s 708us/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0]"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.evaluate(inputs,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "4612ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hold = m3.get_weights()[0]\n",
    "sum(abs(hold[0]))/len(hold[0])\n",
    "for h in range(len(hold)):\n",
    "    for n in range(len(hold[h])):\n",
    "        if((sum(abs(hold[h]))/len(hold[h])) > n):\n",
    "            hold[h][n] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "ac12b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = m3.get_weights()[1]\n",
    "largest_index=0\n",
    "temp = 0\n",
    "for h in range(len(bias)):\n",
    "    if(abs(bias[h])>temp):\n",
    "        temp=abs(bias[h])\n",
    "        largest_index=h\n",
    "if(bias[largest_index] > 0):\n",
    "    bias[largest_index]=bias[largest_index] + 1\n",
    "else:\n",
    "    bias[largest_index]=bias[largest_index] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "4d644a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.layers[0].set_weights([hold, bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "62918576",
   "metadata": {},
   "outputs": [],
   "source": [
    "hold = m3.get_weights()[2]\n",
    "for h in range(len(hold)):\n",
    "    for n in range(len(hold[h])):\n",
    "        if((sum(abs(hold[h]))/len(hold[h])) > n):\n",
    "            hold[h][n] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "16536f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = m3.get_weights()[3]\n",
    "largest_index=0\n",
    "temp = 0\n",
    "for h in range(len(bias)):\n",
    "    if(abs(bias[h])>temp):\n",
    "        temp=abs(bias[h])\n",
    "        largest_index=h\n",
    "if(bias[largest_index] > 0):\n",
    "    bias[largest_index]=bias[largest_index] + 1\n",
    "else:\n",
    "    bias[largest_index]=bias[largest_index] - 1\n",
    "m3.layers[1].set_weights([hold, bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "afcca907",
   "metadata": {},
   "outputs": [],
   "source": [
    "hold = m3.get_weights()[4]\n",
    "for h in range(len(hold)):\n",
    "    for n in range(len(hold[h])):\n",
    "        if((sum(abs(hold[h]))/len(hold[h])) > n):\n",
    "            hold[h][n] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "a5cdaa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = m3.get_weights()[5]\n",
    "largest_index=0\n",
    "temp = 0\n",
    "for h in range(len(bias)):\n",
    "    if(abs(bias[h])>temp):\n",
    "        temp=abs(bias[h])\n",
    "        largest_index=h\n",
    "if(bias[largest_index] > 0):\n",
    "    bias[largest_index]=bias[largest_index] + 1\n",
    "else:\n",
    "    bias[largest_index]=bias[largest_index] - 1\n",
    "m3.layers[2].set_weights([hold, bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "d7c81fe1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-693-e9bccd89e215>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mhold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "hold = m3.get_weights()[6]\n",
    "for h in range(len(hold)):\n",
    "    for n in range(len(hold[h])):\n",
    "        if((sum(abs(hold[h]))/len(hold[h])) > n):\n",
    "            hold[h][n] = 0\n",
    "bias = m3.get_weights()[7]\n",
    "largest_index=0\n",
    "temp = 0\n",
    "for h in range(len(bias)):\n",
    "    if(abs(bias[h])>temp):\n",
    "        temp=abs(bias[h])\n",
    "        largest_index=h\n",
    "if(bias[largest_index] > 0):\n",
    "    bias[largest_index]=bias[largest_index] + 1\n",
    "else:\n",
    "    bias[largest_index]=bias[largest_index] - 1\n",
    "m3.layers[3].set_weights([hold, bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "daa98c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.0000000e+00,  9.2199922e-01, -1.5274959e+00, -3.3022612e-02,\n",
       "          3.0553369e-03, -5.8839500e-02, -4.9899802e-01, -4.4142166e-03,\n",
       "          2.6323631e-01, -4.9707312e-03, -1.0482587e+00,  6.3484836e-01],\n",
       "        [ 0.0000000e+00, -8.0273130e-05, -8.0063790e-02,  2.9687632e-03,\n",
       "         -1.6150920e-03, -1.4591885e-03,  7.1248724e-03,  2.0051427e+00,\n",
       "         -2.2319205e-02, -5.9110438e-03, -3.9190698e-02,  1.7339276e-02],\n",
       "        [ 0.0000000e+00, -4.3483390e-03, -9.4718195e-02,  1.3750407e+00,\n",
       "         -1.8108492e-03, -1.6787726e-03,  1.7598214e-03, -2.7014811e-03,\n",
       "         -6.4542450e-02, -5.9018028e-01, -3.6535274e-02, -7.6086380e-02],\n",
       "        [ 0.0000000e+00, -6.5723702e-04,  2.5190645e-01,  2.7156328e-03,\n",
       "         -1.5075192e-01, -3.0667379e-01, -2.7350727e-01, -6.1157451e-04,\n",
       "          1.4318913e-01, -3.2962137e-01,  1.2954185e-02,  3.6250404e-01]],\n",
       "       dtype=float32),\n",
       " array([-1.5624125 , -1.9197898 ,  1.7893885 , -3.0569737 ,  3.1909606 ,\n",
       "         7.573393  ,  0.831815  , -4.0746083 , -0.9466318 ,  0.93988436,\n",
       "         1.2838095 , -1.8513176 ], dtype=float32),\n",
       " array([[ 0.        ,  0.2817666 ,  0.88048345,  0.27128825],\n",
       "        [ 0.        ,  0.        , -2.8618991 ,  4.2838287 ],\n",
       "        [ 0.        , -1.1195198 ,  0.4234953 , -0.3447931 ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  8.703857  ],\n",
       "        [ 0.        ,  0.        ,  0.        , 11.724727  ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  4.649573  ],\n",
       "        [ 0.        ,  0.        , -2.4172566 ,  2.4251952 ],\n",
       "        [ 0.        ,  0.        , -4.9500656 ,  2.614727  ],\n",
       "        [ 0.        ,  1.4481962 ,  0.23194346,  0.04016789],\n",
       "        [ 0.        ,  0.        , -2.7509944 ,  2.587734  ],\n",
       "        [ 0.        ,  2.5478122 ,  0.39379445,  0.70333564],\n",
       "        [ 0.        ,  0.69143087,  0.31898588,  0.21342903]],\n",
       "       dtype=float32),\n",
       " array([-0.68065214, -6.874535  ,  0.413614  , -0.02831646], dtype=float32),\n",
       " array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=float32),\n",
       " array([3.649312  , 0.35038024], dtype=float32)]"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "id": "6401c2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 2s 653us/step - loss: 1.0729e-11 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.1526e-12 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.1526e-12 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 7.1526e-12 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.1526e-12 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.1526e-12 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 8.3446e-12 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 8.3446e-12 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 7.1526e-12 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 7.1526e-12 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.1526e-12 - accuracy: 1.0000\n",
      "3125/3125 [==============================] - 2s 699us/step - loss: 7.1526e-12 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.9605e-12 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.9605e-12 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.9605e-12 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.9605e-12 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.9605e-12 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.1526e-12 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.9605e-12 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.1526e-12 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.9605e-12 - accuracy: 1.0000\n",
      "3125/3125 [==============================] - 2s 686us/step - loss: 5.9605e-12 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "3125/3125 [==============================] - 2s 733us/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.5763e-12 - accuracy: 1.0000: 0s - loss: 3.6124e-12 - accuracy: \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "3125/3125 [==============================] - 2s 723us/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "3125/3125 [==============================] - 2s 780us/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.7684e-12 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "3125/3125 [==============================] - 3s 833us/step - loss: 3.5763e-12 - accuracy: 1.00000s -\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1921e-12 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1921e-12 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3842e-12 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3842e-12 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3842e-12 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5763e-12 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3842e-12 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3842e-12 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3842e-12 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3842e-12 - accuracy: 1.0000\n",
      "3125/3125 [==============================] - 2s 719us/step - loss: 2.3842e-12 - accuracy: 1.00000s - loss: 2.5078e-12 - accuracy: \n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 1.1921e-12 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.1921e-12 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.1921e-12 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.1921e-12 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.1921e-12 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.1921e-12 - accuracy: 1.0000\n",
      "3125/3125 [==============================] - 2s 676us/step - loss: 1.1921e-12 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.1921e-12 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.1921e-12 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.1921e-12 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.1921e-12 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "3125/3125 [==============================] - 2s 651us/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "while(not(m3.evaluate(inputs,labels)[0] == 0)):\n",
    "    hold = m3.get_weights()[0]\n",
    "    hold = hold * 1.01\n",
    "    bias = m3.get_weights()[7]\n",
    "    bias=bias * (1.01)\n",
    "        \n",
    "    m3.layers[5].set_weights([hold, bias])\n",
    "    hold = m3.get_weights()[8]\n",
    "    hold = hold * 1.01\n",
    "    bias = m3.get_weights()[9]\n",
    "    bias=bias * (1.01)\n",
    "    m3.layers[7].set_weights([hold, bias])\n",
    "    #hold = m3.get_weights()[4]\n",
    "   # hold = hold * 1.01\n",
    "   # bias = m3.get_weights()[5]\n",
    "   # bias=bias * (1.01)\n",
    "    #m3.layers[2].set_weights([hold, bias])\n",
    "      \n",
    "    m3.fit(inputs,labels,epochs = 10, batch_size=1000)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "94575475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-3.8288615e-03, -5.6113810e-03, -6.8355474e-04,  1.6012185e+00],\n",
       "        [ 2.9542521e-03,  1.7197808e+00, -2.1397991e-03,  9.0460908e-03],\n",
       "        [ 1.9271812e+00, -4.5254659e-03,  4.7696754e-05,  3.2305591e-02],\n",
       "        [-3.5424654e-03, -1.1215855e-03, -2.7159753e-01, -3.0541623e-03]],\n",
       "       dtype=float32),\n",
       " array([-3.9164891, -3.4992008,  6.067916 , -3.12012  ], dtype=float32),\n",
       " array([[ 8.025667, -6.472344],\n",
       "        [ 7.422156, -9.18765 ],\n",
       "        [ 9.423856, -9.061647],\n",
       "        [ 8.632292, -9.702135]], dtype=float32),\n",
       " array([-4.6213384,  4.6213512], dtype=float32)]"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "37ed8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = tf.keras.Input(shape=(4,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "id": "1e3b11ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lay1 = k.layers.Dense(16, activation=\"relu\")(input1)\n",
    "lay2 = k.layers.Dense(4, activation=\"relu\")(lay1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "id": "0411629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = k.layers.Dense(2, activation=\"softmax\")(lay2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "a9156bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = tf.keras.Model(inputs=input1,outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "id": "312e1649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 158\n",
      "Trainable params: 158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "id": "8c11d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "id": "a5df16b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 957,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydot\n",
    "tf.keras.utils.plot_model(m3, \"first.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "id": "93ad5bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-3.8288615e-03, -5.6113810e-03, -6.8355474e-04,  1.6012185e+00],\n",
       "        [ 2.9542521e-03,  1.7197808e+00, -2.1397991e-03,  9.0460908e-03],\n",
       "        [ 1.9271812e+00, -4.5254659e-03,  4.7696754e-05,  3.2305591e-02],\n",
       "        [-3.5424654e-03, -1.1215855e-03, -2.7159753e-01, -3.0541623e-03]],\n",
       "       dtype=float32),\n",
       " array([-3.9164891, -3.4992008,  6.067916 , -3.12012  ], dtype=float32),\n",
       " array([[-1.5168874 , -0.0273672 , -0.1667378 ,  0.01548649],\n",
       "        [-0.00270632, -0.04126325,  1.3323166 , -0.00713414],\n",
       "        [ 0.00548839,  0.00406548,  1.095118  , -0.05659039],\n",
       "        [-0.77804846,  0.9301133 , -0.01166762,  0.26914164]],\n",
       "       dtype=float32),\n",
       " array([ 1.085453 , -0.1843228, -0.8481576, -6.2823663], dtype=float32),\n",
       " array([[ 13.325634  , -13.217837  ],\n",
       "        [ 12.225925  , -12.182286  ],\n",
       "        [ 24.383574  , -24.660934  ],\n",
       "        [ 14.96399   , -15.458497  ],\n",
       "        [  4.2091656 ,  -4.883842  ],\n",
       "        [ -0.92543215,   0.42075592],\n",
       "        [ -0.04690108,  -0.5128893 ],\n",
       "        [  2.297088  ,  -2.8494613 ]], dtype=float32),\n",
       " array([ 0.30390933, -0.30689067], dtype=float32)]"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "1df2da57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 4.9801593 , -5.7725606 ],\n",
       "        [ 0.67053866, -0.21763392],\n",
       "        [-0.55430424,  0.043315  ],\n",
       "        [ 2.3289025 , -1.0514792 ],\n",
       "        [ 1.0564799 , -1.2928069 ],\n",
       "        [ 1.8962718 , -2.407633  ],\n",
       "        [-0.4200816 ,  0.2784497 ],\n",
       "        [ 0.44141808, -0.0748942 ]], dtype=float32),\n",
       " array([ 0.28199148, -0.28199077], dtype=float32)]"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.layers[4].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "f7685a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lay1_e1 = tf.keras.layers.Dense(4, activation = \"relu\")(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "id": "e54ffeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lay1_u = tf.keras.layers.Concatenate()([lay1, lay1_e1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "b48567a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 8])"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay1_u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "5663b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = k.layers.Dense(2, activation=\"softmax\")(lay1_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "d817ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4 = tf.keras.Model(inputs=input1, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "e34ded47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_101 (Dense)               (None, 4)            20          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_103 (Dense)               (None, 4)            20          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 8)            0           dense_101[0][0]                  \n",
      "                                                                 dense_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_104 (Dense)               (None, 2)            18          concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 58\n",
      "Trainable params: 38\n",
      "Non-trainable params: 20\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "8772eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4.layers[1].set_weights([m3.get_weights()[0],m3.get_weights()[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "id": "1266593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5.layers[2].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "ec2500ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "bddd4cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to create an array of layer id's. This array wil have a trainbale layer and non trainable layer. Each trainable layer will contain how to access it, and when transfer\n",
    "#is activated, it will be moved to the non trainable folder.\n",
    "layer2 = tf.keras.layers.Dense(8, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "82656f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2=layer2(lay1_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "47ae825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = k.layers.Dense(2, activation=\"softmax\")(layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "32536e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5 = tf.keras.Model(inputs=input1, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "id": "781d5c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_101 (Dense)               (None, 4)            20          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_103 (Dense)               (None, 4)            20          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 8)            0           dense_101[0][0]                  \n",
      "                                                                 dense_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_105 (Dense)               (None, 8)            72          concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_106 (Dense)               (None, 2)            18          dense_105[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 130\n",
      "Trainable params: 90\n",
      "Non-trainable params: 40\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "id": "a45d1ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-3.8288615e-03, -5.6113810e-03, -6.8355474e-04,  1.6012185e+00],\n",
       "        [ 2.9542521e-03,  1.7197808e+00, -2.1397991e-03,  9.0460908e-03],\n",
       "        [ 1.9271812e+00, -4.5254659e-03,  4.7696754e-05,  3.2305591e-02],\n",
       "        [-3.5424654e-03, -1.1215855e-03, -2.7159753e-01, -3.0541623e-03]],\n",
       "       dtype=float32),\n",
       " array([-3.9164891, -3.4992008,  6.067916 , -3.12012  ], dtype=float32),\n",
       " array([[-1.5168874 , -0.0273672 , -0.1667378 ,  0.01548649],\n",
       "        [-0.00270632, -0.04126325,  1.3323166 , -0.00713414],\n",
       "        [ 0.00548839,  0.00406548,  1.095118  , -0.05659039],\n",
       "        [-0.77804846,  0.9301133 , -0.01166762,  0.26914164]],\n",
       "       dtype=float32),\n",
       " array([ 1.085453 , -0.1843228, -0.8481576, -6.2823663], dtype=float32),\n",
       " array([[ 2.243891  , -2.5646477 , -3.0105314 , -0.59271735,  2.628823  ,\n",
       "          2.8840027 ,  3.1566036 , -2.719948  ],\n",
       "        [ 2.883415  , -2.2733643 , -1.9316411 , -0.79909134,  1.7011235 ,\n",
       "          1.3860141 ,  3.076544  , -2.3112648 ],\n",
       "        [ 4.2501364 , -4.300915  , -5.3662415 , -0.13979311,  3.9244645 ,\n",
       "          4.9277306 ,  5.1826525 , -4.810829  ],\n",
       "        [ 3.6146343 , -2.8876119 , -3.6238782 ,  0.17810726,  3.2710972 ,\n",
       "          2.6500342 ,  2.819802  , -3.4599538 ],\n",
       "        [ 1.9399333 , -0.901241  , -1.511699  ,  0.19471022,  1.6763129 ,\n",
       "          1.5220778 ,  1.36695   , -0.6020758 ],\n",
       "        [ 0.47171277,  0.319915  ,  0.5270115 , -0.88946134,  0.4618565 ,\n",
       "          0.16110171, -0.11559854,  0.958711  ],\n",
       "        [ 0.29086277,  0.28744483,  0.13948624, -0.10137971, -0.19432715,\n",
       "          0.09387272,  0.1156325 , -0.08775871],\n",
       "        [ 0.8363047 ,  0.18042983, -0.31983343, -0.1732593 ,  0.10157429,\n",
       "          0.56201017,  1.1644545 ,  0.42004883]], dtype=float32),\n",
       " array([ 0.4879766 , -0.51799184, -0.00831867, -0.4479197 ,  0.3928835 ,\n",
       "         0.45278263,  0.73762614, -0.31654578], dtype=float32),\n",
       " array([[-0.18486527,  0.36178458,  0.5015417 , -0.1376754 ,  0.03854978,\n",
       "          0.00217003,  0.2774896 ,  0.0528506 ],\n",
       "        [-0.29157314, -0.0977031 ,  0.6104216 , -0.06570148, -0.04935867,\n",
       "          0.33562034,  0.16090429, -0.04535782],\n",
       "        [-0.3203546 ,  0.48581272,  0.26679122, -0.55692273,  0.21090484,\n",
       "          0.28579897, -0.04704458, -0.3724816 ],\n",
       "        [-0.49690378, -0.18409291, -0.04918599,  0.32725108,  0.05256766,\n",
       "          0.03789788, -0.19388068, -0.56107724],\n",
       "        [ 0.310476  ,  0.40021795,  0.04706645,  0.600413  , -0.28552213,\n",
       "          0.52919394,  0.20402133,  0.23098946],\n",
       "        [-0.35230267,  0.27058738, -0.30016193,  0.2847613 , -0.23744008,\n",
       "          0.5190849 , -0.22314686, -0.58380884],\n",
       "        [ 0.32801455,  0.32482386, -0.2621154 , -0.5011147 ,  0.3535843 ,\n",
       "          0.41057616, -0.10725671, -0.23913717],\n",
       "        [ 0.10226578, -0.4030072 ,  0.576122  , -0.27191   ,  0.1257242 ,\n",
       "         -0.29254857, -0.5542937 ,  0.04766393]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.53266966,  0.32146156],\n",
       "        [ 0.24782705,  0.49480343],\n",
       "        [-0.24504635, -0.05901855],\n",
       "        [-0.29094073,  0.06116855],\n",
       "        [ 0.53571844,  0.02950305],\n",
       "        [ 0.07842296,  0.17182922],\n",
       "        [ 0.47968948, -0.4097516 ],\n",
       "        [ 0.04099661, -0.37549508],\n",
       "        [ 0.41677386, -0.5674409 ],\n",
       "        [ 0.33197713,  0.5756073 ],\n",
       "        [-0.45832837, -0.52718735],\n",
       "        [-0.4822352 ,  0.4821304 ],\n",
       "        [-0.03949362,  0.5030521 ],\n",
       "        [-0.16932178,  0.4349439 ],\n",
       "        [ 0.42662346, -0.38457316],\n",
       "        [ 0.05003035,  0.19539964]], dtype=float32),\n",
       " array([0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m6.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "072325ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = m6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "e04a2566",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2_e1 = tf.keras.layers.Dense(8, activation=\"relu\")(lay1_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "id": "d7956b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "lay2_u = tf.keras.layers.Concatenate()([layer2, layer2_e1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "1496c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = k.layers.Dense(2, activation=\"softmax\")(lay2_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "id": "8dbc1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "m6 = tf.keras.Model(inputs=input1, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "id": "4bd91e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_101 (Dense)               (None, 4)            20          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_103 (Dense)               (None, 4)            20          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 8)            0           dense_101[0][0]                  \n",
      "                                                                 dense_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_105 (Dense)               (None, 8)            72          concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_107 (Dense)               (None, 8)            72          concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 16)           0           dense_105[0][0]                  \n",
      "                                                                 dense_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 2)            34          concatenate_7[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 218\n",
      "Trainable params: 106\n",
      "Non-trainable params: 112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "id": "782217cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m6.layers[4].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "id": "f5db8bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m7 = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "id": "0c704a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "m7.add(tf.keras.layers.Conv1D(4,(4), activation=\"relu\", padding='same', input_shape=(4,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "7fc0b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m7.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "id": "4839ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m7.add(tf.keras.layers.Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "id": "710b0a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tinputs = inputs.reshape(100000, 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc02e263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "id": "1c5ff109",
   "metadata": {},
   "outputs": [],
   "source": [
    "m7.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "c08c9555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1946 - accuracy: 0.9246\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0781 - accuracy: 0.9670\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0598 - accuracy: 0.9734\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0540 - accuracy: 0.9760\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0488 - accuracy: 0.9786\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0445 - accuracy: 0.9807\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0427 - accuracy: 0.9809\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0400 - accuracy: 0.9825\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0388 - accuracy: 0.9828\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0364 - accuracy: 0.9832\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0348 - accuracy: 0.9842\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0330 - accuracy: 0.9852\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0313 - accuracy: 0.9861\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.98 - 1s 7ms/step - loss: 0.0296 - accuracy: 0.9867\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0278 - accuracy: 0.9879\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0257 - accuracy: 0.9899\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0253 - accuracy: 0.9891\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0232 - accuracy: 0.9910\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0221 - accuracy: 0.9913\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0209 - accuracy: 0.9921\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0207 - accuracy: 0.9922\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0182 - accuracy: 0.9932\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0186 - accuracy: 0.9931\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0181 - accuracy: 0.9936\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0173 - accuracy: 0.9935\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0160 - accuracy: 0.9946\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0166 - accuracy: 0.9942\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0152 - accuracy: 0.9951\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0155 - accuracy: 0.9950\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0159 - accuracy: 0.9947\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0138 - accuracy: 0.9953\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0148 - accuracy: 0.9952\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0130 - accuracy: 0.9955\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0139 - accuracy: 0.9953\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0134 - accuracy: 0.9956\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0146 - accuracy: 0.9956\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0114 - accuracy: 0.9963\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0124 - accuracy: 0.9962\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0135 - accuracy: 0.9956\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0129 - accuracy: 0.9957\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0116 - accuracy: 0.9967\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0131 - accuracy: 0.9960\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0113 - accuracy: 0.9968\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0122 - accuracy: 0.9961\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0108 - accuracy: 0.9966\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0102 - accuracy: 0.9966\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0115 - accuracy: 0.9964\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0107 - accuracy: 0.9966\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0109 - accuracy: 0.9968\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0101 - accuracy: 0.9969\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0108 - accuracy: 0.9968\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0106 - accuracy: 0.9968\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0092 - accuracy: 0.9973\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0108 - accuracy: 0.9967\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0096 - accuracy: 0.9970\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0079 - accuracy: 0.9977\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0101 - accuracy: 0.9971\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0089 - accuracy: 0.9973\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0094 - accuracy: 0.9973\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0081 - accuracy: 0.9972\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0085 - accuracy: 0.9976\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0092 - accuracy: 0.9975\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 0.9975\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0084 - accuracy: 0.9976\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0096 - accuracy: 0.9975\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0084 - accuracy: 0.9977\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0088 - accuracy: 0.9975\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0090 - accuracy: 0.9974\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0065 - accuracy: 0.9980\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0079 - accuracy: 0.9979\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0081 - accuracy: 0.9977\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0071 - accuracy: 0.9982\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0079 - accuracy: 0.9979\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0089 - accuracy: 0.9976\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0077 - accuracy: 0.9978\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0066 - accuracy: 0.9982\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 0.9981\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0079 - accuracy: 0.9979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0066 - accuracy: 0.9981\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0075 - accuracy: 0.9979\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0061 - accuracy: 0.9981\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0085 - accuracy: 0.9979\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0070 - accuracy: 0.9984\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0072 - accuracy: 0.9981\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0074 - accuracy: 0.9981\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0071 - accuracy: 0.9982\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0062 - accuracy: 0.9985\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0070 - accuracy: 0.9980\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0065 - accuracy: 0.9981\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0071 - accuracy: 0.9982\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0065 - accuracy: 0.9985\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 0.9986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2603e5675e0>"
      ]
     },
     "execution_count": 929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m7.fit(tinputs, labels, epochs = 100, batch_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "e4e541ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 4, 4)              20        \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 54\n",
      "Trainable params: 54\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "id": "9dcc35ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x2603e38fc10>"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m7.layers[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "id": "917a043e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 4s 1ms/step - loss: 5.9178e-04 - accuracy: 0.9998\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9989\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9991\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9988\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9993\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9992\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9989\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0055 - accuracy: 0.9990\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9990\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0046 - accuracy: 0.9991\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0040 - accuracy: 0.9991\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0056 - accuracy: 0.9989\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9991\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0056 - accuracy: 0.9993\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9988\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9990\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9991\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0039 - accuracy: 0.9991\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.0044 - accuracy: 0.9990 0s - loss: 0.0045 - accuracy: \n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0047 - accuracy: 0.9991\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9992\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0037 - accuracy: 0.9992\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9989\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0046 - accuracy: 0.9991\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9993\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9991\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9992\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9991\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0048 - accuracy: 0.9990\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9992\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0044 - accuracy: 0.9991\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0058 - accuracy: 0.9991\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 0.9991\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9990\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0063 - accuracy: 0.9990\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9992\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 0.9992\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9989\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0056 - accuracy: 0.9989\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0037 - accuracy: 0.9992\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9992\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9992\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0048 - accuracy: 0.9993\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9992\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 0.9989\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0034 - accuracy: 0.9992\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9989\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 4s 37ms/step - loss: 0.0033 - accuracy: 0.9991 0s - los\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9992\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9988\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9992\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9991\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0048 - accuracy: 0.9991\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9991\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9992\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9992\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 0.0042 - accuracy: 0.9991 1s - ETA: 0s - loss: 0.004\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9990\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9992\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9991\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 0.9990\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9992\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9992\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0048 - accuracy: 0.9990\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9995\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9992\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.0021 - accuracy: 0.9993 1s - - ETA: 0s - loss: 0.0023 - ac\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0054 - accuracy: 0.9990\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 0.9991\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0057 - accuracy: 0.9991\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9994\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9991\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9992\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0019 - accuracy: 0.9992\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0047 - accuracy: 0.9989\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9989\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0038 - accuracy: 0.9994\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9992\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9993\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.0045 - accuracy: 0.9991\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.0034 - accuracy: 0.9992\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9992\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0057 - accuracy: 0.9993\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9991\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9993\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9991\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.0042 - accuracy: 0.9991 0s - loss:\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 0.0030 - accuracy: 0.9995\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9991\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9994 ETA: 0s - loss: 7.7216e\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 0.9992\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9993\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9994\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.0037 - accuracy: 0.9993 0s - loss: 0.0026 - accuracy: 0.\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.0027 - accuracy: 0.9994ETA: 2s - loss:\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9993\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9991\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9993\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9990\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0040 - accuracy: 0.9991\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9995\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9990\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9992\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9995\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9992\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.0040 - accuracy: 0.9992\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.0023 - accuracy: 0.9994 1s - loss: 0.0032  - ETA: 0s - loss: 0.002\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9990\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9994\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9995\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9995\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9995\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0031 - accuracy: 0.9994\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 0.0031 - accuracy: 0.9993 1s - loss: 0.0033 - accuracy: 0. - ETA: 1s - loss: 0.0031  - ETA: 0s - loss: 0.003\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.0034 - accuracy: 0.9994A: 2s -\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9992\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 0.9996\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 0.9991\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0059 - accuracy: 0.9993\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 0.9992\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0053 - accuracy: 0.9994\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0033 - accuracy: 0.9995\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.0040 - accuracy: 0.9991\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 0.9995\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 0.9991\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9994\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9993\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 3.1806e-04 - accuracy: 0.9999\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9993\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9992\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.99 - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.0016 - accuracy: 0.9996 0s - loss: 0\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.0047 - accuracy: 0.9992\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0067 - accuracy: 0.9995\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 0.9996\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.99 - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9993\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0027 - accuracy: 0.9996\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9996\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0031 - accuracy: 0.9994\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9994\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9992\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9996\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 0.9992 0s - loss: 0.0038 - accuracy\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 0.0033 - accuracy: 0.9994 0s - loss: 0.0035 - \n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0035 - accuracy: 0.9994\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9994\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9995\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9992\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.0052 - accuracy: 0.9992 0s - loss: 0.0028 - accuracy: 0.\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.0021 - accuracy: 0.9995ETA: 1s - loss: 6.0\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9995\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9995\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9994\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9992\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9996\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9993\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.0035 - accuracy: 0.9995\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9992\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9992\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9995\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 0.9996\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9996\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9993\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9992\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9995\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 0.0053 - accuracy: 0.9991\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.0032 - accuracy: 0.9995\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9992\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9995\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9995\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9994\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.0037 - accuracy: 0.9992\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9991\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9991\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9994\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9992\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9995\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 0.9994\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 1s 13ms/step - loss: 0.0043 - accuracy: 0.9993\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.0027 - accuracy: 0.9993 0s - loss: 0.0028 - accura\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 1s 12ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9995\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 2.0705e-04 - accuracy: 0.9999\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9994\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9995\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9993\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9996\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9991\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 3s 28ms/step - loss: 0.0031 - accuracy: 0.9995\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 0.9995\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0056 - accuracy: 0.9990\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9995\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9993\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9991\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9994\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 0.9994\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.0042 - accuracy: 0.9993\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9995\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9992\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9993\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0020 - accuracy: 0.9995 0s - loss: 0.0020 - accuracy: 0.99\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.0043 - accuracy: 0.9993\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9994\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9995\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.99 - 1s 6ms/step - loss: 0.0035 - accuracy: 0.9994\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9994\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9992\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9998\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9996\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 0.0053 - accuracy: 0.9992 0s - loss: 0.0\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0025 - accuracy: 0.9995ETA: 2s - loss: 3.0206e\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0035 - accuracy: 0.9995\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0038 - accuracy: 0.9993\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0053 - accuracy: 0.9996\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9993\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.0055 - accuracy: 0.9994\n",
      "Epoch 67/100\n",
      " 79/100 [======================>.......] - ETA: 0s - loss: 0.0037 - accuracy: 0.9994"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-943-7fdc69bfb884>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#m3.layers[2].set_weights([hold, bias])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mm7\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtinputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while(not(m7.evaluate(tinputs,labels)[0] == 0)):\n",
    "    hold = m7.get_weights()[10]\n",
    "    hold = hold * 1.01\n",
    "    bias = m7.get_weights()[11]\n",
    "    bias=bias * (1.01)\n",
    "        \n",
    "    m7.layers[6].set_weights([hold, bias])\n",
    "    #hold = m3.get_weights()[4]\n",
    "   # hold = hold * 1.01\n",
    "   # bias = m3.get_weights()[5]\n",
    "   # bias=bias * (1.01)\n",
    "    #m3.layers[2].set_weights([hold, bias])\n",
    "      \n",
    "    m7.fit(tinputs,labels,epochs = 100, batch_size=1000)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336d3319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
